{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNAg7Fgf4kYZVcpJrJFhr7I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harem123/pandas/blob/main/consumo_cero.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Files importation"
      ],
      "metadata": {
        "id": "auffUk17K66m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SpZFzAE79pEr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97d1e67f-af52-4cf0-9838-d5d1b33d42a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Producto  consumo Fecha_lectura\n",
            "0      152474       62    2023-09-12\n",
            "1      196466       93    2023-09-06\n",
            "2      196842      115    2020-12-30\n",
            "3      229996       55    2023-09-06\n",
            "4      231888       16    2023-09-26\n",
            "..        ...      ...           ...\n",
            "281   8546970      235    2023-09-13\n",
            "282   8546984       63    2023-09-13\n",
            "283   8547862       24    2023-09-13\n",
            "284   8547987        2    2022-09-12\n",
            "285   8549162       98    2023-09-13\n",
            "\n",
            "[286 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "url = 'https://raw.githubusercontent.com/harem123/pandas/main/lecturasv9'\n",
        "\n",
        "df_lecturas = pd.read_csv(url, delimiter=';')\n",
        "urlconsumos = 'https://raw.githubusercontent.com/harem123/pandas/main/consumosv9'\n",
        "df_consumos = pd.read_csv(urlconsumos, delimiter=';')\n",
        "print(df_consumos)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data frames creation\n",
        "consolidate_df  = df_lecturas.iloc[[0]].copy()\n",
        "consolidate_df.loc[consolidate_df.index[0], 'Producto'] = 00000\n",
        "acumulator_df  = df_lecturas.iloc[[0]].copy()\n",
        "acumulator_df.loc[consolidate_df.index[0], 'Producto'] = 00000\n",
        "unsorted_df  = df_consumos.copy()"
      ],
      "metadata": {
        "id": "E254pCkHsXdo"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consumption recreation"
      ],
      "metadata": {
        "id": "Bz8wr4JVjBko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creation of re created consumes\n",
        "consolidate_df  = df_lecturas.iloc[[0]].copy()\n",
        "consolidate_df.loc[consolidate_df.index[0], 'Producto'] = 00000\n",
        "acumulator_df  = df_lecturas.iloc[[0]].copy()\n",
        "acumulator_df.loc[consolidate_df.index[0], 'Producto'] = 00000\n",
        "unsorted_df  = df_consumos.copy()\n",
        "# sort and filter and summarize consumos\n",
        "for i in range (35):\n",
        "  product_base = df_lecturas['Producto'][i]\n",
        "  lect_base = df_lecturas['Lectura_tomada'][i]\n",
        "  fecha_base = df_lecturas['Fecha_lectura'][i]\n",
        "  product = df_consumos['Producto'] == product_base\n",
        "  date_condition = df_consumos['Fecha_lectura'] > fecha_base\n",
        "  sorted_consumos = df_consumos.sort_values(by='Fecha_lectura',ascending=True)\n",
        "  descending_consumos = unsorted_df.sort_values(by='Fecha_lectura',ascending=False)\n",
        "  #descending_consumos.reset_index(drop=True, inplace=True)\n",
        "  filtered_consumos = sorted_consumos[product & date_condition]\n",
        "  filtered_descending_consumos = descending_consumos[product]\n",
        "  filtered_descending_consumos.reset_index(drop=True, inplace=True)\n",
        "  phu  = filtered_descending_consumos.iloc[[0]].copy()\n",
        "  #last_item_in_column = filtered_descending_consumos['fecha'].iloc[-1]\n",
        "  fecha_final2 = phu['Fecha_lectura'][0]\n",
        "  #df3 = pd.concat([df1, df2], ignore_index=True)\n",
        "  sum_of_consumos = filtered_consumos['consumo'].dropna().astype(int).sum()\n",
        "  lectura_final = sum_of_consumos + lect_base\n",
        "  acumulator_df['Producto'] = product_base\n",
        "  acumulator_df['Lectura_tomada'] = lectura_final\n",
        "  acumulator_df['Fecha_lectura'] = fecha_final2\n",
        "  consolidate_df = pd.concat([consolidate_df, acumulator_df], ignore_index=True)\n",
        "\n",
        "print(consolidate_df)\n"
      ],
      "metadata": {
        "id": "ShApJtTJfBsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Export consolidate consumptions"
      ],
      "metadata": {
        "id": "hhEM_ILVXDRW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "\n",
        "#drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "xuSt8_2_XBFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RUFk0HYRXBoV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#obtener por cada producto todos los consumos, ordenarlos de mas antiguo a mas reciente,\n",
        "#filtrar desde la ultima lectura valida y sumar a lectura base\n",
        "#lecturasdf.describe\n",
        "sorted_lecturas = df_lecturas.sort_values(by='fecha_lec')\n",
        "#convert column to date format\n",
        "df_consumos['Fecha_lectura'] = pd.to_datetime(df_consumos['Fecha_lectura'])\n",
        "sorted_consumos = df_consumos.sort_values(by='Fecha_lectura',ascending=True)\n",
        "print(sorted_consumos)"
      ],
      "metadata": {
        "id": "kjHuhEFxgJSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_lecturas['fecha_lec'] = pd.to_datetime(df_lecturas['fecha_lec'])\n",
        "date_condition = df_lecturas['fecha_lec'] > '2018-1-17'\n",
        "product_condition = df_lecturas['Producto'] > 597378\n",
        "\n",
        "# Combine the conditions using the '&' (and) operator\n",
        "filtered_df = df_lecturas[date_condition ]\n",
        "print (filtered_df)"
      ],
      "metadata": {
        "id": "k5TLwMyAof_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# concat 2 df\n",
        "# df3 = pd.concat([df1, df2], ignore_index=True)"
      ],
      "metadata": {
        "id": "QrBLq7LReGdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "product = df_consumos['producto'] == product_base\n",
        "date_condition = df_consumos['Fecha_lectura'] > fecha_base\n",
        "\n",
        "sorted_consumos = df_consumos.sort_values(by='Fecha_lectura',ascending=True)\n",
        "filtered_consumo = sorted_consumos[product & date_condition]\n",
        "print (filtered_consumo)"
      ],
      "metadata": {
        "id": "y78hDe0oiTg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "date_condition = df_consumos['Fecha_lectura'] > fecha_base\n",
        "product_condition = df_consumos['producto'] == product_base\n",
        "\n",
        "# Combine the conditions using the '&' (and) operator\n",
        "filtered_df = df_consumos[date_condition & product_condition]\n",
        "print (filtered_df)"
      ],
      "metadata": {
        "id": "1qcFCPiPhIeL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}